llm:
  extraction_model: "deepseek-v3"
  generation_model: "deepseek-v3"
  temperature: 0.2
  max_tokens: 1024
